# Розділ 12: Цифрові барабани та синхронізація з музикою

> *"My brain is not coping with asynchronous coding well."*
> -- Introspec, file_id.diz для паті-версії Eager (to live), 3BM Open Air 2015

---

Демо -- це не слайд-шоу ефектів. Демо -- це виступ, де кожна візуальна подія потрапляє в такт, кожний перехід дихає з музикою, і глядач ніколи не здогадується, що за лаштунками процесор на 3,5 МГц жонглює половиною десятка конкуруючих вимог без операційної системи, без потоків і без страховки.

Цей розділ присвячено архітектурі, що робить цю жонглерську вправу можливою. Ми провели попередні розділи, створюючи окремі ефекти -- тунелі, зумери, скролери, кольорові анімації -- а в Розділі 11 дізналися, як чип AY виробляє музику. Тепер ми маємо з'єднати все разом. Питання вже не "як намалювати тунель?" чи "як відтворити ноту?", а: Як відтворювати барабанний семпл, що споживає майже весь процесор, зберігаючи плавну візуальну частину? Як синхронізувати зміни ефектів з тактом музики? Як структурувати двохвилинне демо, щоб воно працювало надійно від початку до кінця?

Відповіді приходять з трьох джерел. Eager від Introspec (2015) дає нам цифровий синтез барабанів та асинхронну генерацію кадрів. GABBA від diver4d (2019) показує радикально інший підхід до синхронізації з музикою, використовуючи відеоредактор як інструмент таймлайну. А система потоків від Robus (2015) демонструє, що чесна багатопотоковість на Z80 можлива, хоча й рідко необхідна.

Разом ці три техніки представляють архітектурне мислення, що відрізняє колекцію ефектів від закінченого демо.

---

## 12.1 Цифрові барабани на AY

### Проблема: AY не може відтворювати семпли

AY-3-8910, як ми розглянули в Розділі 11, -- це синтезатор. Він генерує прямокутні хвилі, шум і форми обвідних. У нього немає можливості відтворення семплів, немає ЦАП, немає пам'яті для форм хвиль. Кожний звук, який він видає, будується з цих примітивних джерел у реальному часі. Якщо тобі потрібен реалістичний кік -- такий, з різким перехідним ударом, за яким іде резонансне згасання -- генератор шуму та обвідна AY можуть його апроксимувати, але результат звучить безпомилково синтетично. Йому бракує ваги справжнього перкусійного удару.

Але є чорний хід.

Регістри R8, R9 і R10 контролюють гучність каналів A, B і C. Кожний -- це 4-бітне значення (0-15). Якщо ти записуєш у регістр гучності раз за кадр, отримуєш статичний рівень гучності. А що, якщо записувати в нього тисячі разів за кадр? Що, якщо використовувати регістр гучності як грубий 4-бітний ЦАП і подавати на нього послідовні значення семплів з оцифрованого запису?

Отримуєш відтворення PCM. Грубе, шумне, 4-бітне, але впізнаване. AY стає програвачем семплів -- не за задумом, а грубою силою.

### Ціна: Знищення процесора

Ось проблема. Щоб відтворити оцифрований барабанний семпл з будь-якою прийнятною якістю, потрібно оновлювати регістр гучності зі звуковою частотою. Частота дискретизації 8 кГц означає одне оновлення кожні 125 мікросекунд. На 3,5 МГц 125 мікросекунд -- це приблизно 437 тактів (T-state). Це щільно, але здійсненно -- ти можеш робити корисну роботу в проміжках між записами семплів.

Але 8 кГц звучить жахливо. Для потужного кіку потрібно щонайменше відчуття вищої якості. І тут економіка руйнується. При вищих ефективних частотах дискретизації потрібне переривання або щільний цикл опитування, що спрацьовує кожні 125-250 тактів (T-state). На такій частоті для чого-небудь іншого майже не залишається процесорного часу. Поки барабанний семпл відтворюється, процесор -- це виділений рушій звукового відтворення. Генерація відео, скриптинг, обробка вводу -- все зупиняється.

Типовий семпл кіку триває 20-40 мілісекунд для критичної частини атаки. При 50 Гц це 1-2 кадри. Протягом цих кадрів процесор зайнятий.

### Відкриття n1k-o: Гібридний барабан

n1k-o, музикант саундтреку Eager, знайшов рішення. Ключове спостереження: барабанний звук має дві чіткі фази. **Атака** -- початковий перехідний процес, різкий "клацок" або "удар", що надає кіку його потужність -- коротка, складна і неможлива для переконливого синтезу на AY. Але **згасання** -- резонансний хвіст, що слідує за ним -- це плавний спад гучності, саме те, з чим генератор обвідної AY справляється природно.

Гібридний підхід: відтвори атаку як цифровий семпл (споживаючи процесорний час протягом 1-2 кадрів), потім передай генератору обвідної AY для згасання (споживаючи нуль процесорного часу, оскільки апаратура робить роботу автоматично). Цифрова атака плюс AY-згасання дорівнює барабанному звуку, що має реалістичну потужність семплу та плавний хвіст апаратного синтезу.

На практиці реалізація працює так:

```z80
; Play hybrid kick drum
; 1. Start digital sample playback for attack phase
; 2. When sample ends, configure AY envelope for decay

play_kick_drum:
    di                        ; disable interrupts -- timing critical

    ; --- Digital attack phase ---
    ; Play ~800 samples at ~8kHz = ~100ms = ~2 frames
    ld   hl, kick_sample      ; pointer to 4-bit sample data
    ld   b, 0                 ; 256 samples per loop pass
    ld   c, $FD               ; low byte of AY data port ($BFFD)

    ; Select volume register R8 (channel A)
    ld   a, 8
    ld   bc, $FFFD
    out  (c), a               ; select R8
    ld   c, $FD               ; prepare for $BFFD writes

.sample_loop:
    ld   a, (hl)              ; 7 T  - load sample byte
    inc  hl                   ; 6 T  - advance pointer
    ld   b, $BF               ; 7 T  - high byte of $BFFD
    out  (c), a               ; 12 T - write volume = sample value
    ; ... timing padding to hit target sample rate ...
    djnz .sample_loop         ; 13 T (approx 45 T per sample)

    ; --- AY decay phase ---
    ; Configure envelope for smooth volume decay
    ; The AY takes over -- zero CPU cost from here

    ld   a, R_ENV_LO
    ld   e, 200               ; envelope period: moderate decay speed
    call ay_write
    ld   a, R_ENV_HI
    ld   e, 0
    call ay_write
    ld   a, R_ENV_SHAPE
    ld   e, $00               ; \___  single decay to silence
    call ay_write
    ld   a, R_VOL_A
    ld   e, $10               ; switch channel A to envelope mode
    call ay_write

    ei
    ret

kick_sample:
    ; 4-bit PCM data: attack portion of a kick drum
    ; Each byte = one sample, value 0-15
    DB 0, 2, 8, 15, 14, 12, 15, 13
    DB 10, 14, 11, 8, 12, 9, 6, 10
    ; ... (typically 400-800 bytes for the full attack)
```

Самі дані семплу -- ці 400-800 байт 4-бітного PCM -- походять від реального запису барабана, перетвореного на нижчу частоту дискретизації та квантованого до 4 біт. Перехідний процес атаки зберігає характер оригінального інструмента: молоточок вдаряє по мембрані барабана, початкове стиснення повітря, різкий початок, який наші вуха використовують для ідентифікації звуку. Обвідна AY потім забезпечує чисте, плавне згасання, яке наші вуха приймають як природний резонанс корпусу барабана.

Результат вражаюче переконливий. На чипі, який взагалі не має можливості відтворення семплів, ти чуєш щось схоже на справжній кік. Не студійна якість, навіть не якість Amiga, але на цілі світи краще, ніж чистий синтез AY.

### Бюджет кадру: Два кадри за удар

Вартість у кадрах конкретна: два кадри на кожний удар барабана. Протягом цих кадрів приблизно 140 000 тактів (T-state) (два повних кадрових періоди на Pentagon) споживаються циклом відтворення семплу. Процесор не робить нічого іншого. Дисплей продовжує показувати те, що було в екранній пам'яті, але нові кадри не генеруються. Жодні музичні дані не обробляються (барабан І Є музикою протягом цих двох кадрів). Жоден скриптовий рушій не працює.

Два кадри при 50 Гц -- це 40 мілісекунд. Для музичного треку з кіками на сильну долю при 130 BPM це приблизно один удар кожні 23 кадри. Два кадри з кожних 23, спожиті відтворенням барабана -- близько 9% загального процесорного часу, що подається різкими сплесками, які повністю монополізують процесор.

Це архітектурний виклик, що визначає решту розділу. Як зберегти плавну роботу візуальних ефектів, коли аудіо краде процесор на два кадри за раз, непередбачувано, десятки разів на хвилину?

---

## 12.2 Асинхронна генерація кадрів

### Наївний підхід провалюється

Найпростіша архітектура демо є синхронною: згенеруй один кадр візуального ефекту, дочекайся HALT (vsync), відобрази його. Згенеруй наступний кадр, HALT, відобрази. Це те, що ми будували в кожній практичній вправі до цього моменту. Це працює ідеально, коли генерація кадру займає менше одного кадрового періоду.

Тепер додай цифрові барабани. Музичний рушій сигналізує: "відтвори кік на наступний такт." Процедура відтворення семплу захоплює процесор на два кадри. Протягом цих двох кадрів нові відеокадри не генеруються. Коли барабан завершується, дисплей показував один і той самий кадр три рази (останній згенерований кадр було показано один раз нормально, потім двічі під час удару барабана). Візуальний ефект заїкається.

При одному ударі барабана кожні 23 кадри глядач бачить короткий фріз кожні пів секунди. Це помітно. Це потворно. Це неприйнятно для конкурсного демо.

### Рішення Introspec: Накопичуй кадри

Архітектура Introspec у Eager роз'єднує генерацію кадрів від їх відображення. Візуальний рушій не генерує один кадр і негайно показує його. Натомість він генерує кадри в буфер -- стільки, скільки вміщується -- і система відображення показує їх зі стабільною частотою 50 Гц незалежно від того, що робить генератор.

Механізм -- подвійна буферизація атрибутних кадрів. Дві сторінки атрибутних даних існують у пам'яті. Поки одна сторінка відображається (ULA читає з неї під час оновлення екрану), генератор записує наступний кадр в іншу сторінку. Коли новий кадр готовий, рушій перемикає сторінки: щойно згенерований кадр стає сторінкою відображення, а стара сторінка відображення стає новою ціллю генерації.

```
Time ──────────────────────────────────────────────────►

Display:   [Frame 1] [Frame 2] [Frame 3] [Frame 4] [Frame 5]
Generator: ──gen F2──|──gen F3──|──gen F4──|── DRUM ──|──gen F5──
                                           ↑          ↑
                                      drum starts  drum ends

During the drum hit, the display shows Frame 4 (already generated).
Frame 5 generation resumes immediately after the drum finishes.
```

Але проста подвійна буферизація дає тобі лише один кадр запасу. Якщо барабан споживає два кадри, тобі потрібно було згенерувати два кадри наперед. Ось де асинхронна генерація Introspec дійсно відрізняється від простої подвійної буферизації: рушій може **накопичувати** кілька кадрів наперед.

На 128K Spectrum перемикання банків пам'яті надає простір. Атрибутні кадри малі -- 768 байт кожний. Одна 16-КБ сторінка пам'яті може вмістити приблизно 20 атрибутних кадрів. Генератор працює якнайшвидше, записуючи кадр за кадром у буфер. Система відображення читає з буфера зі стабільною частотою 50 Гц. Коли генератор швидший за реальний час (що зазвичай так, оскільки атрибутна плазма дешева), буфер заповнюється. Коли удар барабана призупиняє генерацію, система відображення витрачає буфер. Поки буфер не вичерпається, глядач бачить плавну анімацію 50 Гц.

### Динаміка буфера

Думай про це як про задачу виробник-споживач, але на машині без паралелізму.

**Виробник** -- це генератор ефекту плазми/тунелю/зумера. Він виробляє атрибутні кадри зі змінною швидкістю -- іноді швидше за 50 Гц (коли обчислення прості і барабани не грають), іноді нуль (під час відтворення барабана).

**Споживач** -- це система відображення, що читає один кадр за оновлення екрану з точною частотою 50 Гц.

**Буфер** знаходиться між ними, поглинаючи різницю.

Динаміка проста:

- **Між ударами барабанів:** Генератор працює швидше, ніж дисплей. Буфер заповнюється. Якщо він досягає ємності, генератор простоює (або рушій просуває стан скрипта).
- **Під час удару барабана:** Генератор зупиняється. Дисплей спустошує буфер з частотою 50 Гц. Двокадровий удар барабана споживає два буферованих кадри.
- **Після удару барабана:** Генератор відновлюється, працюючи якнайшвидше, щоб поповнити буфер перед наступним ударом.

Критичне обмеження: **буфер ніколи не повинен вичерпуватися під час удару барабана.** Якщо два удари барабана відбуваються у швидкій послідовності -- скажімо, кік-малий барабан з інтервалом у два кадри -- буферу потрібен запас щонайменше чотирьох кадрів. Скриптовий рушій Introspec справляється з цим, знаючи музичний таймлайн заздалегідь. Коли наближається щільний барабанний пасаж, рушій генерує додаткові кадри для заповнення буфера. Коли слідує тихий пасаж, буфер природно заповнюється.

Пастка: якщо ритмічний малюнок занадто щільний -- занадто багато ударів занадто близько один до одного -- генератор не встигає. Буфер вичерпується, і дисплей повторює кадр. Це жорстке обмеження архітектури, і воно вплинуло на композицію n1k-o. Музика була написана зі знанням можливостей рушія: удари барабанів рознесені достатньо далеко, щоб генератор завжди міг відновитися. Музикант і кодер проектували разом, кожний розуміючи обмеження іншого.

---

## 12.3 Скриптовий рушій

### Навіщо потрібен скрипт

На цьому етапі список речей, що потребують координації, довгий:

- Генератор візуального ефекту (який ефект активний, які параметри він використовує)
- Музичний програвач (який паттерн грає, коли запускаються барабани)
- Буфер кадрів (наскільки він повний, коли генерувати більше)
- Переходи між ефектами (згасання одного, наростання іншого)
- Загальний таймлайн (демо йде дві хвилини -- що коли відбувається)

Ти міг би захардкодити все це в монолітному головному циклі. Деякі демо так і роблять. Але Introspec обрав інший шлях: дворівневу скриптову систему, що розділяє *що відбувається* від *коли це відбувається*.

### Зовнішній скрипт: Послідовність ефектів

Зовнішній скрипт -- це лінійна послідовність команд, що контролюють загальну структуру демо. Думай про нього як про сетліст для концерту:

```
; Outer script (conceptual, not exact syntax)
EFFECT  tunnel, params_set_1     ; start the tunnel effect
WAIT    200                       ; run for 200 frames (4 seconds)
EFFECT  zoomer, params_set_1     ; switch to chaos zoomer
WAIT    150                       ; 3 seconds
EFFECT  tunnel, params_set_2     ; tunnel again, different colours
WAIT    250                       ; 5 seconds
; ... and so on for the full demo
```

Кожна команда `EFFECT` завантажує функцію генератора та його блок параметрів. Кожна `WAIT` повідомляє рушію, скільки кадрів запускати поточний ефект перед переходом до наступної команди. Переходи між ефектами -- кросфейди, різкі зрізи, кольорові свіпи -- самі є скриптованими як ефекти.

### Внутрішній скрипт: Варіації всередині ефекту

В межах одного ефекту параметри змінюються з часом. Частоти плазми тунелю зсуваються, кольорова палітра обертається, швидкість зуму прискорюється. Ці варіації контролюються внутрішнім скриптом -- послідовністю змін параметрів для кожного ефекту, прив'язаних до номерів кадрів:

```
; Inner script for tunnel effect (conceptual)
FRAME  0:   plasma_freq = 3, palette = warm
FRAME  50:  plasma_freq = 5                   ; frequency shift
FRAME  100: palette = cool                     ; colour change
FRAME  120: plasma_freq = 2, palette = hot     ; both change
```

Внутрішній скрипт працює незалежно від зовнішнього скрипта. Коли зовнішній скрипт каже "запусти тунель на 200 кадрів", внутрішній скрипт обробляє візуальну еволюцію в межах цих 200 кадрів.

### kWORK: Ключова команда

Найважливіша команда у скриптовій системі -- те, що Introspec називає **kWORK**: "згенеруй N кадрів, потім покажи їх незалежно від генерації." Ця єдина команда є мостом між скриптовою системою та асинхронною архітектурою.

Коли рушій зустрічає `kWORK 8`, він:

1. Генерує 8 кадрів поточного ефекту в буфер кадрів.
2. Передає ці кадри системі відображення.
3. Поки система відображення показує їх (протягом 8/50 = 160 мс), рушій вільний робити іншу роботу: обробити наступну команду скрипта, підготувати наступну партію або віддати процесорний час для відтворення барабана.

Це роз'єднання -- генеруй зараз, відображай пізніше -- є фундаментальним активатором асинхронної роботи. Без kWORK рушій був би замкнений у синхронному циклі генерація-відображення-генерація-відображення без запасу для барабанних переривань.

На практиці рушій викликає kWORK повторно, генеруючи малі партії кадрів (4-8 за раз). Між партіями він перевіряє, чи очікується тригер барабана. Якщо так, він дозволяє барабану зіграти, знаючи, що система відображення має достатньо буферованих кадрів для плавного продовження. Після завершення барабана він генерує наступну партію для поповнення буфера.

```z80
; Simplified engine loop (conceptual)
engine_loop:
    ; Check if drum is pending
    ld   a, (drum_pending)
    or   a
    jr   z, .no_drum
    call play_drum            ; consumes 2 frames of CPU time
    xor  a
    ld   (drum_pending), a

.no_drum:
    ; Generate a batch of frames
    call generate_batch       ; kWORK: produce N frames into buffer
    ; (generate_batch returns when batch is done)

    ; Check outer script for effect changes
    call advance_script

    jr   engine_loop
```

Краса цієї архітектури -- в її простоті на макрорівні. Рушій -- це цикл: перевір барабани, згенеруй кадри, просунь скрипт. Вся складність знаходиться всередині `generate_batch` (що керує буфером, обробляє обчислення плазми та записує атрибутні дані) та `play_drum` (що запускає процедуру цифрового семплу з розділу 12.1). Скриптова система забезпечує послідовність; буфер забезпечує часове роз'єднання; процедура барабана забезпечує звуковий вплив. Кожний компонент має чітку відповідальність.

---

## 12.4 Інновація GABBA: Відеоредактор як інструмент таймлайну

У 2019 році diver4d (з 4th Dimension) зайняв перше місце на CAFe з GABBA -- демо у стилі габбер з нещадно щільною аудіовізуальною синхронізацією. Синхронізація була настільки точною, що кожний візуальний удар потрапляв рівно на музичний такт, кожний перехід збігався з межею фрази, і вся продукція відчувалася як музичний кліп, а не як демо.

Технічний сюрприз був у робочому процесі, а не в коді.

### Проблема з синхронізацією на основі коду

Традиційний підхід до синхронізації з музикою у ZX-демо -- це вбудовування тайм-даних у код. Ти знаєш, що кік потрапляє на кадр 47, тому пишеш команду скрипта, що запускає візуальну подію на кадрі 47. Потім дивишся демо, вирішуєш, що таймінг трохи не той, змінюєш число на 49, перекомпілюєш, перетестовуєш і повторюєш. Для двохвилинного демо при 50 fps це 6 000 кадрів потенційних точок синхронізації. Вивести їх усі правильно методом спроб і помилок займає тижні.

Eager від Introspec було побудовано саме так, і розробка була виснажливою. Кожна корекція синхронізації вимагала перекомпіляції -- збірка Z80-коду, завантаження бінарного файлу в емулятор, перегляд відповідного фрагменту, нотування того, що не так, редагування вихідного коду та повторення. Цикл зворотного зв'язку вимірювався хвилинами за ітерацію.

### Відповідь diver4d: Luma Fusion

diver4d повністю обійшов цикл код-редагування-компіляція-тест. Він використав **Luma Fusion**, iOS-відеоредактор, як свій інструмент синхронізації.

Робочий процес:

1. **n1k-o створив габбер-трек** з покадровими структурними маркерами. Музикант і кодер працювали з одним документом: таймлайном, де кожний такт, кожний філ, кожний брейкдаун був позначений номером кадру. Це був не приблизний орієнтир темпу -- це була покадрово точна карта всього треку.

2. **diver4d записав кожний візуальний ефект**, що працює при 50 fps в емуляторі, і експортував записи як відеокліпи.

3. **У Luma Fusion** він розклав відеокліпи на таймлайні 50 fps поруч з аудіотреком. Він міг прокручувати демо покадрово, бачачи, як саме кожний візуальний елемент узгоджується з кожною музичною подією. Переміщення переходу було таким же простим, як перетягування кліпу на таймлайні.

4. **Коли таймінг був правильним у редакторі**, він витягнув номери кадрів для кожного переходу та зміни ефекту і записав ці числа у скрипт-дані Z80.

Ідея оманливо проста: використовуй правильний інструмент для завдання. Відеоредактор створений спеціально для покадрової мультимедійної синхронізації. Асемблер Z80 -- ні. Виконуючи творчу роботу із синхронізації в редакторі, а реалізацію в асемблері, diver4d відокремив мистецькі рішення від інженерних обмежень.

### Що це змінює

Безпосередня вигода -- швидкість. Коригування тайм-синхронізації у відеоредакторі займає секунди. В асемблері -- хвилини. При сотнях точок синхронізації кумулятивна економія часу величезна. Але глибша вигода -- творча свобода. Коли ітерація дешева, ти більше експериментуєш. Ти пробуєш перехід на два кадри раніше, дивишся, як це відчувається, пробуєш на два кадри пізніше. Ти помічаєш, що візуальний ефект працює краще, коли потрапляє трохи *до* такту (техніка, запозичена з кіномонтажу, де зрізи на такт здаються запізнілими через час реакції людини). Ти ніколи не зміг би виявити це через ітерацію на основі коду -- цикл зворотного зв'язку занадто повільний.

Обмеження в тому, що цей робочий процес найкраще працює для демо з фіксованим таймінгом -- де демо завжди відтворюється однаково. Якщо ти хочеш інтерактивні або генеративні елементи, що реагують на умови виконання, тобі потрібен підхід на основі коду. Але для переважної більшості ZX-демо, які є лінійними продукціями з фіксованим таймлайном, робочий процес з відеоредактором кращий.

GABBA продемонстрував, що інструменти виробництва на демосцені не зобов'язані бути ретро. Z80-код з 1985 року. Робочий процес синхронізації може бути з 2019 року. Немає суперечності.

---

## 12.5 Потоки на Z80: Інший шлях

Robus, пишучи в Hype у 2015 році, представив техніку, що атакує проблему паралелізму з зовсім іншого боку: справжня багатопотоковість на Z80.

### Проблема, переформульована

Фундаментальна напруга в рушії демо полягає в тому, що кілька завдань потребують процесорного часу в одному кадрі: генерація ефектів, відтворення музики, барабанні семпли, скриптинг, переходи. Рішення Introspec -- кооперативне: рушій вручну чергує ці завдання за допомогою скриптової системи та буфера кадрів. Це працює, але вимагає ретельного ручного планування та всієї асинхронної архітектури, яку ми обговорювали.

А що, якби Z80 міг виконувати два завдання одночасно?

### Перемикання контексту на основі IM2

Він може, у певному сенсі. IM2-переривання Z80 забезпечує природну точку перемикання контексту. Кожний кадр переривання спрацьовує. Якщо обробник переривань зберігає стан поточного завдання та завантажує стан іншого завдання, ти маєш витісняючу багатопотоковість.

Процедура `SwitchThread` від Robus робить саме це:

```z80
; SwitchThread: save current thread, resume next thread
; Called from within the IM2 interrupt handler
SwitchThread:
    ; Save current thread's stack pointer
    ld   (thread_sp_save), sp

    ; Save current memory page configuration
    ld   a, (current_7ffd)
    ld   (thread_page_save), a

    ; Load next thread's state
    ld   a, (next_thread_page)
    ld   (current_7ffd), a
    ld   bc, $7FFD
    out  (c), a               ; switch memory page

    ld   sp, (next_thread_sp)  ; switch stack pointer

    ; Execution continues in the next thread's context
    ; (it was previously suspended at this same point)
    ret
```

Кожний потік отримує власний **128-байтний стек** та **виділену сторінку пам'яті** (один з восьми 16-КБ банків 128K Spectrum). Стек малий, але достатній -- Z80-код рідко має глибоке вкладення. Виділена сторінка пам'яті дає кожному потоку власний робочий простір без втручання в інший.

### Як це працює на практиці

У демо WAYHACK від Robus два потоки працюють паралельно:

- **Потік 1:** Обчислює візуальний ефект (рендерер перспективи подземелля-краулера).
- **Потік 2:** Рендерить текст, що прокручується внизу екрана.

Жоден потік не знає про інший. Кожний працює у власній сторінці пам'яті з власним стеком. Кожний кадр IM2-переривання спрацьовує, і `SwitchThread` чергує між ними. Потік 1 отримує один кадр процесорного часу, потім Потік 2 отримує один кадр, і так далі.

Результат: текстовий скролер працює зі стабільною частотою 25 Гц (кожний другий кадр), і візуальний ефект працює на 25 Гц. Жоден з потоків не потребує знання про існування іншого. Ніякого кооперативного планування, ніяких точок поступки, ніякого ручного чергування. Переривання обробляє все.

### Модель потоків

Модель проста:

```
Frame 1: Interrupt → save Thread 2 → restore Thread 1 → Thread 1 runs
Frame 2: Interrupt → save Thread 1 → restore Thread 2 → Thread 2 runs
Frame 3: Interrupt → save Thread 2 → restore Thread 1 → Thread 1 runs
...
```

Кожний потік бачить узгоджений світ: свої регістри, свій стек, свою сторінку пам'яті. Перемикання відбувається у фіксованій точці (переривання), тому немає умов гонки на спільних даних. Якщо потокам потрібно спілкуватися (наприклад, Потік 1 сигналізує Потоку 2 змінити текст), вони роблять це через спільну комірку пам'яті, до якої обидва потоки мають доступ -- простий прапорець або поштова скринька.

### Практичні міркування

Власна оцінка Robus характерно чесна: **"Чесна багатопотоковість рідко вимагає більше двох потоків"** на Z80. Накладні витрати на перемикання контексту (збереження та відновлення SP плюс перемикання сторінки пам'яті) помірні -- можливо, 100 тактів (T-state) -- але кожний додатковий потік вдвічі зменшує доступний процесорний час на потік. З двома потоками кожний отримує 25 Гц. З трьома кожний отримує приблизно 16,7 Гц. На машині, де візуальна плавність вимагає близько 50 Гц, два потоки -- це практична межа.

Потоковий підхід ортогональний підходу асинхронної буферизації Introspec. Ти можеш поєднати їх: один потік генерує кадри ефектів у буфер, тоді як інший обробляє музику та відтворення барабанів. На практиці така комбінація рідкісна -- дві техніки вирішують ту саму проблему (чергування ресурсоємних завдань) різними механізмами, і більшість демо-кодерів обирають одну або іншу на основі конкретних вимог свого виробництва.

Потоки працюють найкраще, коли два завдання дійсно незалежні і жодне не потребує більше 25 Гц. Підхід з асинхронним буфером працює найкраще, коли одне завдання (візуальне) потребує 50 Гц, а інше (барабани) потребує непередбачуваних сплесків. Для архітектури Eager, де візуальна плавність була першорядною і барабанний таймінг диктувався музикою, підхід з буфером переміг. Для архітектури WAYHACK, де два стабільних завдання працювали паралельно, перемогли потоки.

---

## 12.6 Практика: Мінімальний скриптований рушій демо

Побудуймо мінімальний рушій демо, що зв'язує воєдино концепції з цього розділу. Мета -- не витонченість рівня Eager -- це скелет, що демонструє архітектуру.

### Що ми будуємо

- **Три прості ефекти:** плазма (на основі атрибутів, з Розділу 9), кольорові смуги (горизонтальні атрибутні стрічки) та текстовий скролер.
- **AY-музика**, що відтворюється через переривання IM2 (з використанням програвача .pt3, як описано в Розділі 11).
- **Цифровий кік-семпл**, що грає на такт, забираючи 2 кадри процесора.
- **Простий скрипт таймлайну**, що перемикає між ефектами у визначених точках.
- **Подвійна буферизація атрибутів** для поглинання пауз від ударів барабана.

### Карта пам'яті

```
$6000-$7FFF   Engine code + effect routines
$8000-$9FFF   Music player + song data
$A000-$AFFF   Sine tables, colour maps, sample data
$B000-$BFFF   Frame ring buffer (attribute frames)
$C000-$DFFF   Shadow screen (second display page)
$E000-$FFFF   Stack + IM2 vector table + workspace

Bank 0-3:     Not used (available for larger effects)
Bank 5:       Normal screen ($4000-$5AFF display)
Bank 7:       Shadow screen ($C000-$DAFF display)
```

### Скрипт таймлайну

```z80
; Timeline script: sequence of (effect_id, duration_frames, param_ptr)
timeline:
    DB  EFFECT_PLASMA,   0, 150   ; plasma for 150 frames (3 sec)
    DW  plasma_params_1
    DB  EFFECT_BARS,     0, 100   ; colour bars for 100 frames (2 sec)
    DW  bars_params_1
    DB  EFFECT_SCROLLER, 0, 200   ; text scroller for 200 frames (4 sec)
    DW  scroller_params_1
    DB  EFFECT_PLASMA,   0, 150   ; plasma again, different params
    DW  plasma_params_2
    DB  $FF                        ; end marker: loop from start

EFFECT_PLASMA   EQU 0
EFFECT_BARS     EQU 1
EFFECT_SCROLLER EQU 2
```

### Головний цикл рушія

```z80
; Main engine loop
; Assumes IM2 is set up and music player runs in the ISR

engine_init:
    ; Set up display: fill pixel memory with checkerboard
    call fill_checkerboard

    ; Initialise ring buffer
    xor  a
    ld   (buf_write_idx), a
    ld   (buf_read_idx), a
    ld   (buf_count), a

    ; Load first effect from timeline
    ld   hl, timeline
    ld   (script_ptr), hl
    call load_next_effect

engine_main:
    ; === Step 1: Check for drum trigger ===
    ld   a, (drum_pending)
    or   a
    jr   z, .no_drum

    ; Play the drum -- this consumes ~2 frames
    call play_kick_drum
    xor  a
    ld   (drum_pending), a
    jr   .after_drum

.no_drum:
    ; === Step 2: Generate a frame into the buffer ===
    ld   a, (buf_count)
    cp   BUF_CAPACITY         ; buffer full?
    jr   nc, .buffer_full

    ; Generate one frame of the current effect
    call generate_frame       ; writes 768 bytes to ring buffer

    ; Advance buffer write pointer
    ld   a, (buf_write_idx)
    inc  a
    cp   BUF_CAPACITY
    jr   nz, .no_wrap_w
    xor  a
.no_wrap_w:
    ld   (buf_write_idx), a
    ld   a, (buf_count)
    inc  a
    ld   (buf_count), a

.buffer_full:
.after_drum:
    ; === Step 3: Advance timeline ===
    ld   hl, (frame_counter)
    inc  hl
    ld   (frame_counter), hl

    ; Check if current effect duration has elapsed
    ld   de, (effect_duration)
    or   a
    sbc  hl, de
    jr   c, .effect_continues

    ; Load next effect from timeline
    call load_next_effect
    ld   hl, 0
    ld   (frame_counter), hl

.effect_continues:
    ; === Step 4: Wait if we are ahead of display ===
    halt                      ; sync to frame boundary

    jr   engine_main
```

### ISR відображення

```z80
; IM2 interrupt handler: runs every frame (50 Hz)
frame_isr:
    push af
    push bc
    push de
    push hl

    ; Play music (updates AY registers)
    call music_play

    ; Check if music engine signals a drum hit
    ld   a, (music_drum_flag)
    or   a
    jr   z, .no_drum_signal
    xor  a
    ld   (music_drum_flag), a
    ld   a, 1
    ld   (drum_pending), a    ; signal main loop
.no_drum_signal:

    ; Display next frame from ring buffer
    ld   a, (buf_count)
    or   a
    jr   z, .no_frame         ; buffer empty, keep current frame

    ; Copy buffered attributes to display page
    call copy_buf_to_screen

    ; Advance read pointer
    ld   a, (buf_read_idx)
    inc  a
    cp   BUF_CAPACITY
    jr   nz, .no_wrap_r
    xor  a
.no_wrap_r:
    ld   (buf_read_idx), a
    ld   a, (buf_count)
    dec  a
    ld   (buf_count), a

.no_frame:
    pop  hl
    pop  de
    pop  bc
    pop  af
    ei
    reti

BUF_CAPACITY EQU 8           ; 8 frames of buffer (8 x 768 = 6,144 bytes)
```

### Диспетчер генератора ефектів

```z80
; Generate one frame of the current effect
; Writes attribute data to the ring buffer
generate_frame:
    ld   a, (current_effect)
    or   a
    jr   z, .do_plasma
    cp   1
    jr   z, .do_bars
    cp   2
    jr   z, .do_scroller
    ret

.do_plasma:
    call calc_plasma          ; from Chapter 9 -- writes 768 bytes
    ret
.do_bars:
    call calc_colour_bars     ; horizontal attribute stripes
    ret
.do_scroller:
    call calc_text_scroll     ; text rendering into attributes
    ret
```

### Спостереження

Цей скелет навмисно простий. Виробничий рушій додав би:

- **Внутрішні скрипти** для варіації параметрів у межах кожного ефекту.
- **Ефекти переходу** (кросфейди між двома атрибутними буферами).
- **Кілька барабанних звуків** (кік, малий барабан, хай-хет), кожний зі своїми даними семплу.
- **Моніторинг рівня буфера**, щоб генератор міг пріоритизувати наздоганяння після щільних барабанних пасажів.
- **Перемикання банків пам'яті** для зберігання більшої кількості кадрів та підтримки більших даних ефектів.

Але навіть у цій мінімальній формі архітектура демонструє ключові принципи:

1. **Роз'єднання генерації та відображення.** Генератор і ISR відображення спілкуються лише через кільцевий буфер. Жоден з них не знає і не турбується про таймінг іншого.

2. **Удари барабана поглинаються буфером.** Коли `play_kick_drum` споживає два кадри, ISR відображення продовжує показувати буферовані кадри. Глядач не бачить заїкання.

3. **Скрипт керує таймлайном.** Додавання нового ефекту або зміна послідовності означає редагування таблиці даних `timeline`, а не реструктуризацію коду рушія.

4. **Музичний програвач працює в ISR.** Він оновлює регістри AY кожний кадр незалежно від того, що робить головний цикл. Єдина взаємодія -- це прапорець `drum_pending` -- однобайтова поштова скринька між ISR та головним циклом.

Це і є архітектура демо. Не ефекти, не музика, не арт -- *сантехніка*, що змушує все це працювати разом. Це найменш видима частина демо і найскладніша для правильної реалізації. Introspec провів десять тижнів над Eager, і архітектура спожила більше цього часу, ніж будь-який окремий ефект.

---

## 12.7 Практичні вправи

**Вправа 1: Базовий рушій.** Реалізуй скелет вище з одним ефектом (плазма з Розділу 9) і без барабанних семплів. Перевір, що кільцевий буфер працює правильно: дисплей показує плавну анімацію, поки генератор працює з природною швидкістю.

**Вправа 2: Додай барабан.** Запиши (або синтезуй) 4-бітний кік-семпл (400-800 байт). Додай процедуру `play_kick_drum` і запускай її кожні 25 кадрів. Перевір, що дисплей залишається плавним під час відтворення барабана. Яка максимальна частота ударів барабана, перш ніж буфер вичерпається?

**Вправа 3: Багатоефектний таймлайн.** Додай другий ефект (кольорові смуги або текстовий скролер). Напиши скрипт таймлайну, що перемикає між ефектами кожні 3-4 секунди. Перевір, що переходи відбуваються на правильному кадрі.

**Вправа 4: Синхронізація з музикою.** Завантаж короткий трек .pt3 і модифікуй програвач, щоб він встановлював `music_drum_flag`, коли відбувається певна подія в паттерні (наприклад, нота на каналі C нижче певної висоти). Тепер барабани керуються музикою, а не фіксованим лічильником кадрів. Це справжня музична синхронізація.

**Вправа 5: Робочий процес з відеоредактором.** Запиши своє працююче демо в емуляторі при 50 fps. Імпортуй запис у відеоредактор (будь-який редактор, що підтримує покадрове редагування). Відкоригуй номери кадрів скрипту таймлайну на основі того, що ти бачиш у редакторі. Відчуй різницю у швидкості ітерації порівняно із синхронізацією лише через код.

---

## Підсумок

Цей розділ був не про окремий ефект чи техніку. Він був про архітектуру -- невидиму структуру, що дозволяє демо існувати як зв'язаний, синхронізований двохвилинний виступ, а не як колекція розрізнених екранів.

Ключові проблеми є універсальними. Кожний рушій демо має відповісти: Як ділити процесор між аудіо та відео? Як зберегти плавність дисплея, коли аудіо забирає час обробки? Як послідовно відтворювати ефекти та синхронізувати їх з музикою? Як керувати таймлайном багатохвилинного виробництва?

Рішення, які ми розглянули, є взаємодоповнюючими:

- **Цифрові барабани** (n1k-o/Introspec) використовують регістри гучності AY як грубий ЦАП, змішуючи цифрові семпли з апаратним синтезом для створення перкусії, що перевершує проектні можливості чипа.
- **Асинхронна генерація кадрів** (Introspec) роз'єднує виробництво відео від відображення через кільцевий буфер, поглинаючи процесорні сплески, спожиті відтворенням барабанів.
- **Скриптовані таймлайни** (Introspec) відокремлюють *що* і *коли* демо від *як*, даючи можливість проектувати та коригувати двохвилинне виробництво без реструктуризації рушія.
- **Синхронізація через відеоредактор** (diver4d) переносить творчу роботу з таймінгом у інструмент, спеціально створений для цього, драматично прискорюючи цикл ітерації синхронізації.
- **Потоки Z80** (Robus) забезпечують справжній паралелізм для завдань, що є незалежними та стабільними, ціною вдвічі зниженої частоти кадрів для кожного завдання.

Цим розділом ми замикаємо коло демосценної частини книги. Ми побудували ефекти (Частини I-II), створили звук (Розділ 11) і тепер з'єднали все у працюючий рушій. Читач, який слідкував від Розділу 1, має повну картину: від підрахунку тактів (T-state) до синхронізованого, скриптованого демо з цифровими барабанами.

У наступному розділі ми радикально змінюємо напрямок. Частина IV переносить нас у sizecoding -- мистецтво вміщення цілого виробництва у 256 байт. Архітектура змінюється від "як мені керувати кільцевим буфером?" до "як змусити кожний окремий байт виконувати подвійну функцію?" Обмеження стискаються на три порядки, і мислення змінюється відповідно.

---

> **Джерела:** Introspec, "Making of Eager," Hype, 2015 (hype.retroscene.org/blog/demo/261.html); Introspec, file_id.diz from Eager (to live), 3BM Open Air 2015; diver4d, "Making of GABBA," Hype, 2019 (hype.retroscene.org/blog/demo/948.html); Robus, "Threads on Z80," Hype, 2015 (hype.retroscene.org/blog/dev/271.html); Eager source code excerpts courtesy of Introspec (Life on Mars)
